{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pytholog (Write Prolog in Python) Overview Python library that enables using logic programming in python. The aim of the library is to explore ways to use symbolic reasoning with machine learning. Pytholog supports probabilities. Pytholog gives facts indices (first term) and uses binary search to search for relevant facts instead of looping over all knowledge base. So when defining rules, make sure that the main search terms are in the first position to speed up the search queries. There is a SourceForge project, available here: https://sourceforge.net/projects/pytholog/, that has an executable tool that works as a standalone logical database with a RESTful API that can be queried by and used with other applications. The tools in the project work in Linux and Windows and there is also the script to be built on OSX system. prolog syntax Prolog takes facts and rules. A fact or a rule has a predicate which in \u201clikes(noor, sausage)\u201d is \u201clikes\u201d and in \u201cfriend(X, Y)\u201d is \u201cfriend\u201d. Rules have \u201cLeft Hand Side (LHS)\u201d which has a predicate and \u201cRight Hand Sides (RHS)\u201d or \u201cgoals\u201d to be searched to answer the queries about the rules. LHS and RHS in a rule are separated with \u201c:-\u201d. Each predicate has \u201cTerms\u201d. Prolog uses lowercased variables to describe \u201cconstant values\u201d and uppercased values to describe \u201cvariables\u201d that need to be updated from the query. Let\u2019s take an example: likes(noor, sausage) is a fact which has likes as a predicate and (noor and sausage) as terms. friend(X, Y) :- +(X = Y), likes(X, Z), likes(Y, Z) is a rule which defines that two persons are considered friends if they like the same dish. This rule has an LHS friend(X, Y) and RHS or goals [+(X = Y), likes(X, Z), likes(Y, Z)] . The comma separating the goals means and while ; will mean or . Variables in the fact are lowercased meaning they are truths and cannot change. While in a rule they are Uppercased meaning they need to be changed while in a query. Prolog uses backtracking search to answer the questions and the queries. I loved prolog and the idea of Symbolic Intelligence. So I decided to build a module or a framework in python that can allow me to use prolog inside python aiming to combine the power of machine learning and symbolic reasoning.","title":"Home"},{"location":"#pytholog-write-prolog-in-python","text":"","title":"pytholog (Write Prolog in Python)"},{"location":"#overview","text":"Python library that enables using logic programming in python. The aim of the library is to explore ways to use symbolic reasoning with machine learning. Pytholog supports probabilities. Pytholog gives facts indices (first term) and uses binary search to search for relevant facts instead of looping over all knowledge base. So when defining rules, make sure that the main search terms are in the first position to speed up the search queries. There is a SourceForge project, available here: https://sourceforge.net/projects/pytholog/, that has an executable tool that works as a standalone logical database with a RESTful API that can be queried by and used with other applications. The tools in the project work in Linux and Windows and there is also the script to be built on OSX system.","title":"Overview"},{"location":"#prolog-syntax","text":"Prolog takes facts and rules. A fact or a rule has a predicate which in \u201clikes(noor, sausage)\u201d is \u201clikes\u201d and in \u201cfriend(X, Y)\u201d is \u201cfriend\u201d. Rules have \u201cLeft Hand Side (LHS)\u201d which has a predicate and \u201cRight Hand Sides (RHS)\u201d or \u201cgoals\u201d to be searched to answer the queries about the rules. LHS and RHS in a rule are separated with \u201c:-\u201d. Each predicate has \u201cTerms\u201d. Prolog uses lowercased variables to describe \u201cconstant values\u201d and uppercased values to describe \u201cvariables\u201d that need to be updated from the query. Let\u2019s take an example: likes(noor, sausage) is a fact which has likes as a predicate and (noor and sausage) as terms. friend(X, Y) :- +(X = Y), likes(X, Z), likes(Y, Z) is a rule which defines that two persons are considered friends if they like the same dish. This rule has an LHS friend(X, Y) and RHS or goals [+(X = Y), likes(X, Z), likes(Y, Z)] . The comma separating the goals means and while ; will mean or . Variables in the fact are lowercased meaning they are truths and cannot change. While in a rule they are Uppercased meaning they need to be changed while in a query. Prolog uses backtracking search to answer the questions and the queries. I loved prolog and the idea of Symbolic Intelligence. So I decided to build a module or a framework in python that can allow me to use prolog inside python aiming to combine the power of machine learning and symbolic reasoning.","title":"prolog syntax"},{"location":"How%20pytholog%20works/","text":"Logic Programming with Pytholog Getting Started Installation pip install pytholog import pytholog as pl Defining a knowledge base object to store the facts and rules. new_kb = pl.KnowledgeBase(\"flavor\") new_kb([\"likes(noor, sausage)\", \"likes(melissa, pasta)\", \"likes(dmitry, cookie)\", \"likes(nikita, sausage)\", \"likes(assel, limonade)\", \"food_type(gouda, cheese)\", \"food_type(ritz, cracker)\", \"food_type(steak, meat)\", \"food_type(sausage, meat)\", \"food_type(limonade, juice)\", \"food_type(cookie, dessert)\", \"flavor(sweet, dessert)\", \"flavor(savory, meat)\", \"flavor(savory, cheese)\", \"flavor(sweet, juice)\", \"food_flavor(X, Y) :- food_type(X, Z), flavor(Y, Z)\", \"dish_to_like(X, Y) :- likes(X, L), food_type(L, T), flavor(F, T), food_flavor(Y, F), neq(L, Y)\"]) Note that neq() is pytholog's way to apply inequality so here \"neq(L, Y)\" means L != Y meaning that we look for new dishes not the one already liked by the person in the query. OR can be implemented with defining the rules as many times as the OR facts. For example, to say \"fly(X) :- bird(X) ; wings(X).\" can be defined as two rules as follows: \"fly(X) :- bird(X).\" and \"fly(X) :- wings(X).\" Let\u2019s do some queries in this database using its facts and rules. new_kb.query(pl.Expr(\"likes(noor, sausage)\")) # ['Yes'] new_kb.query(pl.Expr(\"likes(noor, pasta)\")) # ['No'] Memoization I added Memoization to speed up the queries. Wikipedia definition: In computing, memoization or memoisation is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again. Let\u2019s test it doing the same query twice and compare time used to do the query. # query 1 from time import time start = time() print(new_kb.query(pl.Expr(\"food_flavor(What, sweet)\"))) print(time() - start) # [{'What': 'limonade'}, {'What': 'cookie'}] # 0.0020236968994140625 # query 2 start = time() print(new_kb.query(pl.Expr(\"food_flavor(Food, sweet)\"))) print(time() - start) # [{'Food': 'limonade'}, {'Food': 'cookie'}] # 0.0 As you see, it took almost no time to return the same answer again and it also takes care of different Uppercased variable inputs as they anyways will be the same result no matter what they are. Nested rules Now we will use the dish_to_like rule to recommend dishes to persons based on taste preferences. start = time() print(new_kb.query(pl.Expr(\"dish_to_like(noor, What)\"))) print(time() - start) # [{'What': 'gouda'}, {'What': 'steak'}] # 0.001992940902709961 Let\u2019s test the Memoization again: start = time() print(new_kb.query(pl.Expr(\"dish_to_like(noor, What)\"))) print(time() - start) # [{'What': 'gouda'}, {'What': 'steak'}] # 0.0 Constraint Satisfaction Problem City Coloring problem Image source: Seven Languages in Seven Weeks Book The problem is Constraint Satisfaction Problem . The problem is to color each city using only three colors but no adjacent cities can be colored the same. The problem might seem so easy but it\u2019s really challenging how to tell this to a machine. But using prolog logic it is kind of easier because all you have to do is to specify the rules of the problem and prolog will answer. ## new knowledge base object city_color = pl.KnowledgeBase(\"city_color\") city_color([ \"different(red, green)\", \"different(red, blue)\", \"different(green, red)\", \"different(green, blue)\", \"different(blue, red)\", \"different(blue, green)\", \"coloring(A, M, G, T, F) :- different(M, T),different(M, A),different(A, T),different(A, M),different(A, G),different(A, F),different(G, F),different(G, T)\" ]) Let\u2019s query the answer: ## we will use [0] to return only one answer ## as prolog will give all possible combinations and answers city_color.query(pl.Expr(\"coloring(Alabama, Mississippi, Georgia, Tennessee, Florida)\"), cut = True) # {'Alabama': 'blue', # 'Mississippi': 'red', # 'Georgia': 'red', # 'Tennessee': 'green', # 'Florida': 'green'} Probabilistic Logic Now let's try to play with some probabilities. First in prolog \"is\" is used to assign the result of operations. For example, if we want to say \"A = 3 * 4\", we say \"A is 3 * 4\", not \"A = 3 * 4\" because this is unification not assignment. Let's define some dummy knowledge base with probabilities and query them: The numbers are totally dummy and have no meanings just to explain the functionality. battery_kb = pl.KnowledgeBase(\"battery\") battery_kb([ \"battery(dead,P) :- voltmeter(battery_terminals,abnormal,P2), P is P2 + 0.5\", \"battery(dead,P) :- electrical_problem(P), P >= 0.8\", \"battery(dead,P) :- electrical_problem(P2), age(battery,old,P3), P is P2 * P3 * 0.9\", \"electrical_problem(0.7)\", \"age(battery,old, 0.8)\", \"voltmeter(battery_terminals,abnormal,0.3)\"]) battery_kb.query(pl.Expr(\"battery(dead, Probability)\")) # [{'Probability': 0.8}, {'Probability': 'No'}, {'Probability': 0.504}] # the second one is \"No\" because the condition has not been met. Rules from Machine Learning Taking rules from Machine Learning model and feed them into knowledge base then try to predict new instances. This shows beneficial for Explainable AI . One can explain why a model predicts specific prediction. Let's suppose that we have these rules from a Decision Tree Model to classify iris flowers. And we have a new record for which we try to predict using the rules. iris_kb = pl.KnowledgeBase(\"iris\") iris_kb([## Rules \"species(setosa, Truth) :- petal_width(W), Truth is W <= 0.80\", \"species(versicolor, Truth) :- petal_width(W), petal_length(L), Truth is W > 0.80 and L <= 4.95\", \"species(virginica, Truth) :- petal_width(W), petal_length(L), Truth is W > 0.80 and L > 4.95\", ## New record \"petal_length(5.1)\", \"petal_width(2.4)\"]) Now let's try to predict the class: iris_kb.query(pl.Expr(\"species(Class, Truth)\")) # [{'Class': 'setosa', 'Truth': 'No'}, # {'Class': 'versicolor', 'Truth': 'No'}, # {'Class': 'virginica', 'Truth': 'Yes'}] Now let's extract the rules for some goal or fact. iris_kb.rule_search(pl.Expr(\"species(Species, Truth)\")) # [species(setosa,Truth):-petal_width(W),TruthisW<=0.80, # species(versicolor,Truth):-petal_width(W),petal_length(L),TruthisW>0.80andL<=4.95, # species(virginica,Truth):-petal_width(W),petal_length(L),TruthisW>0.80andL>4.95] So now we can see the rules why a model chooses a prediction and explain the behavior. Helper Functions clear_cache() is used to clean the cache inside the knowledge_base: new_kb.clear_cache() from_file() is used to read facts and rules from a prolog ,pl, or txt file: example_kb = pl.KnowledgeBase(\"example\") example_kb.from_file(\"/examples/example.txt\") # facts and rules have been added to example.db example_kb.query(pl.Expr(\"food_flavor(What, savory)\")) # [{'What': 'gouda'}, {'What': 'steak'}, {'What': 'sausage'}] Also we can constructs rules or facts looping over dataframes: import pandas as pd df = pd.DataFrame({\"has_work\": [\"david\", \"daniel\"], \"tasks\": [8, 3]}) df # has_work tasks #0 david 8 #1 daniel 3 ex = pl.KnowledgeBase() for i in range(df.shape[0]): ex([f\"has_work({df.has_work[i]}, {df.tasks[i]})\"]) ex.db # {'has_work': {'facts': [has_work(david,8), has_work(daniel,3)], # 'goals': [[], []], # 'terms': [['david', '8'], ['daniel', '3']]}} Graph Traversals with Pytholog Let's define a weighted directed graph and see if we can get a path, hopefully the shortest, between two nodes using breadth first search. Image Source graph = pl.KnowledgeBase(\"graph\") graph([ \"edge(a, b, 6)\", \"edge(a, c, 1)\", \"edge(b, e, 4)\", \"edge(b, f, 3)\", \"edge(c, d, 3)\", \"edge(d, e, 8)\", \"edge(e, f, 2)\", \"path(X, Y, W) :- edge(X , Y, W)\", \"path(X, Y, W) :- edge(X, Z, W1), path(Z, Y, W2), W is W1 + W2\"]) answer, path = graph.query(pl.Expr(\"path(a, f, W)\"), show_path = True) print(answer) print([x for x in path if str(x) > \"Z\"]) # [{'W': 9}, {'W': 12}, {'W': 14}] # ['d', 'b', 'e', 'c'] Now with the show_path argument we can see the nodes the search passed by and we can see it gave all the possible answers and the first one is the best. So let's use the cut argument to get only the first result and stop the search. answer, path = graph.query(pl.Expr(\"path(a, e, W)\"), show_path = True, cut = True) print(answer) print([x for x in path if str(x) > \"Z\"]) # [{'W': 10}] # ['b'] Future implementation will try to come up with ideas to combine this technique with machine learning algorithms and neural networks Contribution, ideas and any kind of help will be much appreciated","title":"Logic Programming with Pytholog"},{"location":"How%20pytholog%20works/#logic-programming-with-pytholog","text":"","title":"Logic Programming with Pytholog"},{"location":"How%20pytholog%20works/#getting-started","text":"Installation pip install pytholog import pytholog as pl Defining a knowledge base object to store the facts and rules. new_kb = pl.KnowledgeBase(\"flavor\") new_kb([\"likes(noor, sausage)\", \"likes(melissa, pasta)\", \"likes(dmitry, cookie)\", \"likes(nikita, sausage)\", \"likes(assel, limonade)\", \"food_type(gouda, cheese)\", \"food_type(ritz, cracker)\", \"food_type(steak, meat)\", \"food_type(sausage, meat)\", \"food_type(limonade, juice)\", \"food_type(cookie, dessert)\", \"flavor(sweet, dessert)\", \"flavor(savory, meat)\", \"flavor(savory, cheese)\", \"flavor(sweet, juice)\", \"food_flavor(X, Y) :- food_type(X, Z), flavor(Y, Z)\", \"dish_to_like(X, Y) :- likes(X, L), food_type(L, T), flavor(F, T), food_flavor(Y, F), neq(L, Y)\"]) Note that neq() is pytholog's way to apply inequality so here \"neq(L, Y)\" means L != Y meaning that we look for new dishes not the one already liked by the person in the query. OR can be implemented with defining the rules as many times as the OR facts. For example, to say \"fly(X) :- bird(X) ; wings(X).\" can be defined as two rules as follows: \"fly(X) :- bird(X).\" and \"fly(X) :- wings(X).\" Let\u2019s do some queries in this database using its facts and rules. new_kb.query(pl.Expr(\"likes(noor, sausage)\")) # ['Yes'] new_kb.query(pl.Expr(\"likes(noor, pasta)\")) # ['No']","title":"Getting Started"},{"location":"How%20pytholog%20works/#memoization","text":"I added Memoization to speed up the queries. Wikipedia definition: In computing, memoization or memoisation is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again. Let\u2019s test it doing the same query twice and compare time used to do the query. # query 1 from time import time start = time() print(new_kb.query(pl.Expr(\"food_flavor(What, sweet)\"))) print(time() - start) # [{'What': 'limonade'}, {'What': 'cookie'}] # 0.0020236968994140625 # query 2 start = time() print(new_kb.query(pl.Expr(\"food_flavor(Food, sweet)\"))) print(time() - start) # [{'Food': 'limonade'}, {'Food': 'cookie'}] # 0.0 As you see, it took almost no time to return the same answer again and it also takes care of different Uppercased variable inputs as they anyways will be the same result no matter what they are.","title":"Memoization"},{"location":"How%20pytholog%20works/#nested-rules","text":"Now we will use the dish_to_like rule to recommend dishes to persons based on taste preferences. start = time() print(new_kb.query(pl.Expr(\"dish_to_like(noor, What)\"))) print(time() - start) # [{'What': 'gouda'}, {'What': 'steak'}] # 0.001992940902709961 Let\u2019s test the Memoization again: start = time() print(new_kb.query(pl.Expr(\"dish_to_like(noor, What)\"))) print(time() - start) # [{'What': 'gouda'}, {'What': 'steak'}] # 0.0","title":"Nested rules"},{"location":"How%20pytholog%20works/#constraint-satisfaction-problem","text":"City Coloring problem","title":"Constraint Satisfaction Problem"},{"location":"How%20pytholog%20works/#image-source-seven-languages-in-seven-weeks-book","text":"The problem is Constraint Satisfaction Problem . The problem is to color each city using only three colors but no adjacent cities can be colored the same. The problem might seem so easy but it\u2019s really challenging how to tell this to a machine. But using prolog logic it is kind of easier because all you have to do is to specify the rules of the problem and prolog will answer. ## new knowledge base object city_color = pl.KnowledgeBase(\"city_color\") city_color([ \"different(red, green)\", \"different(red, blue)\", \"different(green, red)\", \"different(green, blue)\", \"different(blue, red)\", \"different(blue, green)\", \"coloring(A, M, G, T, F) :- different(M, T),different(M, A),different(A, T),different(A, M),different(A, G),different(A, F),different(G, F),different(G, T)\" ]) Let\u2019s query the answer: ## we will use [0] to return only one answer ## as prolog will give all possible combinations and answers city_color.query(pl.Expr(\"coloring(Alabama, Mississippi, Georgia, Tennessee, Florida)\"), cut = True) # {'Alabama': 'blue', # 'Mississippi': 'red', # 'Georgia': 'red', # 'Tennessee': 'green', # 'Florida': 'green'}","title":"Image source: Seven Languages in Seven Weeks Book"},{"location":"How%20pytholog%20works/#probabilistic-logic","text":"Now let's try to play with some probabilities. First in prolog \"is\" is used to assign the result of operations. For example, if we want to say \"A = 3 * 4\", we say \"A is 3 * 4\", not \"A = 3 * 4\" because this is unification not assignment. Let's define some dummy knowledge base with probabilities and query them: The numbers are totally dummy and have no meanings just to explain the functionality. battery_kb = pl.KnowledgeBase(\"battery\") battery_kb([ \"battery(dead,P) :- voltmeter(battery_terminals,abnormal,P2), P is P2 + 0.5\", \"battery(dead,P) :- electrical_problem(P), P >= 0.8\", \"battery(dead,P) :- electrical_problem(P2), age(battery,old,P3), P is P2 * P3 * 0.9\", \"electrical_problem(0.7)\", \"age(battery,old, 0.8)\", \"voltmeter(battery_terminals,abnormal,0.3)\"]) battery_kb.query(pl.Expr(\"battery(dead, Probability)\")) # [{'Probability': 0.8}, {'Probability': 'No'}, {'Probability': 0.504}] # the second one is \"No\" because the condition has not been met.","title":"Probabilistic Logic"},{"location":"How%20pytholog%20works/#rules-from-machine-learning","text":"Taking rules from Machine Learning model and feed them into knowledge base then try to predict new instances. This shows beneficial for Explainable AI . One can explain why a model predicts specific prediction. Let's suppose that we have these rules from a Decision Tree Model to classify iris flowers. And we have a new record for which we try to predict using the rules. iris_kb = pl.KnowledgeBase(\"iris\") iris_kb([## Rules \"species(setosa, Truth) :- petal_width(W), Truth is W <= 0.80\", \"species(versicolor, Truth) :- petal_width(W), petal_length(L), Truth is W > 0.80 and L <= 4.95\", \"species(virginica, Truth) :- petal_width(W), petal_length(L), Truth is W > 0.80 and L > 4.95\", ## New record \"petal_length(5.1)\", \"petal_width(2.4)\"]) Now let's try to predict the class: iris_kb.query(pl.Expr(\"species(Class, Truth)\")) # [{'Class': 'setosa', 'Truth': 'No'}, # {'Class': 'versicolor', 'Truth': 'No'}, # {'Class': 'virginica', 'Truth': 'Yes'}] Now let's extract the rules for some goal or fact. iris_kb.rule_search(pl.Expr(\"species(Species, Truth)\")) # [species(setosa,Truth):-petal_width(W),TruthisW<=0.80, # species(versicolor,Truth):-petal_width(W),petal_length(L),TruthisW>0.80andL<=4.95, # species(virginica,Truth):-petal_width(W),petal_length(L),TruthisW>0.80andL>4.95] So now we can see the rules why a model chooses a prediction and explain the behavior.","title":"Rules from Machine Learning"},{"location":"How%20pytholog%20works/#helper-functions","text":"clear_cache() is used to clean the cache inside the knowledge_base: new_kb.clear_cache() from_file() is used to read facts and rules from a prolog ,pl, or txt file: example_kb = pl.KnowledgeBase(\"example\") example_kb.from_file(\"/examples/example.txt\") # facts and rules have been added to example.db example_kb.query(pl.Expr(\"food_flavor(What, savory)\")) # [{'What': 'gouda'}, {'What': 'steak'}, {'What': 'sausage'}] Also we can constructs rules or facts looping over dataframes: import pandas as pd df = pd.DataFrame({\"has_work\": [\"david\", \"daniel\"], \"tasks\": [8, 3]}) df # has_work tasks #0 david 8 #1 daniel 3 ex = pl.KnowledgeBase() for i in range(df.shape[0]): ex([f\"has_work({df.has_work[i]}, {df.tasks[i]})\"]) ex.db # {'has_work': {'facts': [has_work(david,8), has_work(daniel,3)], # 'goals': [[], []], # 'terms': [['david', '8'], ['daniel', '3']]}}","title":"Helper Functions"},{"location":"How%20pytholog%20works/#graph-traversals-with-pytholog","text":"Let's define a weighted directed graph and see if we can get a path, hopefully the shortest, between two nodes using breadth first search.","title":"Graph Traversals with Pytholog"},{"location":"How%20pytholog%20works/#image-source","text":"graph = pl.KnowledgeBase(\"graph\") graph([ \"edge(a, b, 6)\", \"edge(a, c, 1)\", \"edge(b, e, 4)\", \"edge(b, f, 3)\", \"edge(c, d, 3)\", \"edge(d, e, 8)\", \"edge(e, f, 2)\", \"path(X, Y, W) :- edge(X , Y, W)\", \"path(X, Y, W) :- edge(X, Z, W1), path(Z, Y, W2), W is W1 + W2\"]) answer, path = graph.query(pl.Expr(\"path(a, f, W)\"), show_path = True) print(answer) print([x for x in path if str(x) > \"Z\"]) # [{'W': 9}, {'W': 12}, {'W': 14}] # ['d', 'b', 'e', 'c'] Now with the show_path argument we can see the nodes the search passed by and we can see it gave all the possible answers and the first one is the best. So let's use the cut argument to get only the first result and stop the search. answer, path = graph.query(pl.Expr(\"path(a, e, W)\"), show_path = True, cut = True) print(answer) print([x for x in path if str(x) > \"Z\"]) # [{'W': 10}] # ['b'] Future implementation will try to come up with ideas to combine this technique with machine learning algorithms and neural networks Contribution, ideas and any kind of help will be much appreciated","title":"Image Source"},{"location":"friends_influence/","text":"Probabilistic Logic How friends can influence each other into smoking based on some other factors. The example is inspired by problog Here how we can define the knowledge base in Prolog : stress(X, P) :- has_lot_work(X, P2), P is P2 * 0.2. to_smoke(X, Prob) :- stress(X, P1), friends(Y, X), influences(Y, X, P2), smokes(Y), Prob is P1 * P2. to_have_asthma(X, 0.4) :- smokes(X). to_have_asthma(X, Prob) :- to_smoke(X, P2), Prob is P2 * 0.25. friends(X, Y) :- friend(X, Y). friends(X, Y) :- friend(Y, X). influences(X, Y, 0.6) :- friends(X, Y). friend(peter, david). friend(peter, rebecca). friend(daniel, rebecca). smokes(peter). smokes(rebecca). has_lot_work(daniel, 0.8). has_lot_work(david, 0.3). So much similar in python with pytholog : friends_kb = pl.KnowledgeBase(\"friends\") friends_kb([ \"stress(X, P) :- has_lot_work(X, P2), P is P2 * 0.2\", \"to_smoke(X, Prob) :- stress(X, P1), friends(Y, X), influences(Y, X, P2), smokes(Y), Prob is P1 * P2\", \"to_have_asthma(X, 0.4) :- smokes(X)\", \"to_have_asthma(X, Prob) :- to_smoke(X, P2), Prob is P2 * 0.25\", \"friends(X, Y) :- friend(X, Y)\", \"friends(X, Y) :- friend(Y, X)\", \"influences(X, Y, 0.6) :- friends(X, Y)\", \"friend(peter, david)\", \"friend(peter, rebecca)\", \"friend(daniel, rebecca)\", \"smokes(peter)\", \"smokes(rebecca)\", \"has_lot_work(daniel, 0.8)\", \"has_lot_work(david, 0.3)\" ]) Let's now perform some queries in both languages: Prolog: influences(X, rebecca, P). % P = 0.59999999999999998 % X = peter ? ; % P = 0.59999999999999998 % X = daniel ? ; smokes(Who). % Who = peter ? ; % Who = rebecca ; to_smoke(Who, P). % P = 0.096000000000000016 % Who = daniel ? ; % P = 0.035999999999999997 % Who = david ? ; to_have_asthma(Who, P). % P = 0.40000000000000002 % Who = peter ? ; % P = 0.40000000000000002 % Who = rebecca ? ; % P = 0.024000000000000004 % Who = daniel ? ; % P = 0.0089999999999999993 % Who = david ? ; Python: friends_kb.query(pl.Expr(\"influences(X, rebecca, P)\")) # [{'X': 'peter', 'P': '0.6'}, {'X': 'daniel', 'P': '0.6'}] friends_kb.query(pl.Expr(\"smokes(Who)\")) # [{'Who': 'peter'}, {'Who': 'rebecca'}] friends_kb.query(pl.Expr(\"to_smoke(Who, P)\")) # [{'Who': 'daniel', 'P': 0.09600000000000002}, {'Who': 'david', 'P': 0.036}] friends_kb.query(pl.Expr(\"to_have_asthma(Who, P)\")) # [{'Who': 'peter', 'P': '0.4'}, # {'Who': 'rebecca', 'P': '0.4'}, # {'Who': 'daniel', 'P': 0.024000000000000004}, # {'Who': 'david', 'P': 0.009}] The two languages are performing the same way and giving the same results! :D This is the purpose of pytholog, to mimic the way prolog behaves inside python.","title":"Probabilistic Logic"},{"location":"friends_influence/#probabilistic-logic","text":"How friends can influence each other into smoking based on some other factors. The example is inspired by problog Here how we can define the knowledge base in Prolog : stress(X, P) :- has_lot_work(X, P2), P is P2 * 0.2. to_smoke(X, Prob) :- stress(X, P1), friends(Y, X), influences(Y, X, P2), smokes(Y), Prob is P1 * P2. to_have_asthma(X, 0.4) :- smokes(X). to_have_asthma(X, Prob) :- to_smoke(X, P2), Prob is P2 * 0.25. friends(X, Y) :- friend(X, Y). friends(X, Y) :- friend(Y, X). influences(X, Y, 0.6) :- friends(X, Y). friend(peter, david). friend(peter, rebecca). friend(daniel, rebecca). smokes(peter). smokes(rebecca). has_lot_work(daniel, 0.8). has_lot_work(david, 0.3). So much similar in python with pytholog : friends_kb = pl.KnowledgeBase(\"friends\") friends_kb([ \"stress(X, P) :- has_lot_work(X, P2), P is P2 * 0.2\", \"to_smoke(X, Prob) :- stress(X, P1), friends(Y, X), influences(Y, X, P2), smokes(Y), Prob is P1 * P2\", \"to_have_asthma(X, 0.4) :- smokes(X)\", \"to_have_asthma(X, Prob) :- to_smoke(X, P2), Prob is P2 * 0.25\", \"friends(X, Y) :- friend(X, Y)\", \"friends(X, Y) :- friend(Y, X)\", \"influences(X, Y, 0.6) :- friends(X, Y)\", \"friend(peter, david)\", \"friend(peter, rebecca)\", \"friend(daniel, rebecca)\", \"smokes(peter)\", \"smokes(rebecca)\", \"has_lot_work(daniel, 0.8)\", \"has_lot_work(david, 0.3)\" ]) Let's now perform some queries in both languages: Prolog: influences(X, rebecca, P). % P = 0.59999999999999998 % X = peter ? ; % P = 0.59999999999999998 % X = daniel ? ; smokes(Who). % Who = peter ? ; % Who = rebecca ; to_smoke(Who, P). % P = 0.096000000000000016 % Who = daniel ? ; % P = 0.035999999999999997 % Who = david ? ; to_have_asthma(Who, P). % P = 0.40000000000000002 % Who = peter ? ; % P = 0.40000000000000002 % Who = rebecca ? ; % P = 0.024000000000000004 % Who = daniel ? ; % P = 0.0089999999999999993 % Who = david ? ; Python: friends_kb.query(pl.Expr(\"influences(X, rebecca, P)\")) # [{'X': 'peter', 'P': '0.6'}, {'X': 'daniel', 'P': '0.6'}] friends_kb.query(pl.Expr(\"smokes(Who)\")) # [{'Who': 'peter'}, {'Who': 'rebecca'}] friends_kb.query(pl.Expr(\"to_smoke(Who, P)\")) # [{'Who': 'daniel', 'P': 0.09600000000000002}, {'Who': 'david', 'P': 0.036}] friends_kb.query(pl.Expr(\"to_have_asthma(Who, P)\")) # [{'Who': 'peter', 'P': '0.4'}, # {'Who': 'rebecca', 'P': '0.4'}, # {'Who': 'daniel', 'P': 0.024000000000000004}, # {'Who': 'david', 'P': 0.009}] The two languages are performing the same way and giving the same results! :D This is the purpose of pytholog, to mimic the way prolog behaves inside python.","title":"Probabilistic Logic"},{"location":"pytholog_database/","text":"Pytholog as a logic database Overview We will use DVD Rental database to feed a knowledge base as facts and rules, then logically query the database. Here we can find how to create the database in postgresql and insert the data. Let's connect to the database in python and see how it looks like: import psycopg2 import pandas as pd psql = psycopg2.connect(host = \"localhost\", database = \"dvdrental\", user = \"postgres\", password = \"password\") cursor = psql.cursor() ## fetch some data to confirm connection pd.read_sql(\"SELECT * FROM language;\", psql) # language_id name last_update # 0 1 English 2006-02-15 10:02:19 # 1 2 Italian 2006-02-15 10:02:19 # 2 3 Japanese 2006-02-15 10:02:19 # 3 4 Mandarin 2006-02-15 10:02:19 # 4 5 French 2006-02-15 10:02:19 # 5 6 German 2006-02-15 10:02:19 Let's see what the table names are: cursor.execute(\"select relname from pg_class where relkind='r' and relname !~ '^(pg_|sql_)';\") print(cursor.fetchall()) # [('actor',), ('store',), ('address',), ('category',), ('city',), ('country',), # ('customer',), ('film_actor',), ('film_category',), ('inventory',), ('language',), # ('rental',), ('staff',), ('payment',), ('film',), ('movies_rental',), ('compressed_movies_rental',)] def query_defn(table): return f\"SELECT * FROM {table};\" Reading tables into python No we will read the tables we will query into python and do some transformation to have values in lowercase. actor = pd.read_sql(query_defn(\"actor\"), psql) actor[\"Actor\"] = (actor[\"first_name\"] + \"_\" + actor[\"last_name\"]).str.lower() actor.head() # actor_id first_name ... last_update Actor # 0 1 Penelope ... 2013-05-26 14:47:57.620 penelope_guiness # 1 2 Nick ... 2013-05-26 14:47:57.620 nick_wahlberg # 2 3 Ed ... 2013-05-26 14:47:57.620 ed_chase # 3 4 Jennifer ... 2013-05-26 14:47:57.620 jennifer_davis # 4 5 Johnny ... 2013-05-26 14:47:57.620 johnny_lollobrigida # [5 rows x 5 columns] language = pd.read_sql(query_defn(\"language\"), psql) film = pd.read_sql(query_defn(\"film\"), psql) category = pd.read_sql(query_defn(\"category\"), psql) #customer = pd.read_sql(query_defn(\"customer\"), psql) language[\"name\"] = language[\"name\"].str.lower() film[\"title\"] = film[\"title\"].str.replace(\" \", \"_\").str.lower() category[\"name\"] = category[\"name\"].str.lower() #customer[\"Customer\"] = (customer[\"first_name\"] + \"_\" + customer[\"last_name\"]).str.lower() film_category = pd.read_sql(query_defn(\"film_category\"), psql) #film[film.film_id.isin(film_category[film_category.category_id == 14].film_id)] print(film.loc[film.film_id == 1, \"title\"]) # 4 academy_dinosaur # Name: title, dtype: object print(actor.head()) # actor_id first_name ... last_update Actor # 0 1 Penelope ... 2013-05-26 14:47:57.620 penelope_guiness # 1 2 Nick ... 2013-05-26 14:47:57.620 nick_wahlberg # 2 3 Ed ... 2013-05-26 14:47:57.620 ed_chase # 3 4 Jennifer ... 2013-05-26 14:47:57.620 jennifer_davis # 4 5 Johnny ... 2013-05-26 14:47:57.620 johnny_lollobrigida Defining Knowledge Base Let's initiate the knowledge base and feed it with for loops. We will use rules as the query statements and views if we need some joining and conditions. import pytholog as pl dvd = pl.KnowledgeBase(\"dvd_rental\") for i in range(film.shape[0]): dvd([f\"film({film.film_id[i]}, {film.title[i]}, {film.language_id[i]})\"]) for i in range(language.shape[0]): dvd([f\"language({language.language_id[i]}, {language.name[i]})\"]) ## simple query dvd([\"film_language(F, L) :- film(_, F, LID), language(LID, L)\"]) dvd.query(pl.Expr(\"film_language(young_language, L)\")) # [{'L': 'english'}] Rules as views film_category We will create film_category view for i in range(category.shape[0]): dvd([f\"category({category.category_id[i]}, {category.name[i]})\"]) for i in range(film_category.shape[0]): dvd([f\"filmcategory({film_category.film_id[i]}, {film_category.category_id[i]})\"]) dvd([\"film_category(F, C) :- film(FID, F, _), filmcategory(FID, CID), category(CID, C)\"]) ## \"_\" to neglect this term ## another query to see what films in sci-fi category dvd.query(pl.Expr(\"film_category(F, sci-fi)\")) # [{'F': 'annie_identity'}, # {'F': 'armageddon_lost'}, # ..... # {'F': 'titans_jerk'}, # {'F': 'trojan_tomorrow'}, # {'F': 'unforgiven_zoolander'}, # {'F': 'vacation_boondock'}, # {'F': 'weekend_personal'}, # {'F': 'whisperer_giant'}, # {'F': 'wonderland_christmas'}] film_actor Let's join actors and films for i in range(actor.shape[0]): dvd([f\"actor({actor.actor_id[i]}, {actor.Actor[i]})\"]) film_actor = pd.read_sql(query_defn(\"film_actor\"), psql) #print(film_actor[film_actor[\"actor_id\"] == 3].shape) print(film_actor.shape) #(5462, 3) for i in range(film_actor.shape[0]): dvd([f\"filmactor({film_actor.film_id[i]}, {film_actor.actor_id[i]})\"]) dvd([\"film_actor(F, A) :- film(FID, F, _), filmactor(FID, AID), actor(AID, A)\"]) dvd.query(pl.Expr(\"film_actor(annie_identity, Actor)\")) #[{'Actor': 'adam_grant'}, {'Actor': 'cate_mcqueen'}, {'Actor': 'greta_keitel'}] ## query actors in a film dvd.query(pl.Expr(\"film_actor(academy_dinosaur, Actor)\")) # [{'Actor': 'penelope_guiness'}, # {'Actor': 'christian_gable'}, # {'Actor': 'lucille_tracy'}, # {'Actor': 'sandra_peck'}, # {'Actor': 'johnny_cage'}, # {'Actor': 'mena_temple'}, # {'Actor': 'warren_nolte'}, # {'Actor': 'oprah_kilmer'}, # {'Actor': 'rock_dukakis'}, # {'Actor': 'mary_keitel'}] ### query films that an actor performed in dvd.query(pl.Expr(\"film_actor(Film, penelope_guiness)\")) # [{'Film': 'academy_dinosaur'}, # {'Film': 'anaconda_confessions'}, # {'Film': 'angels_life'}, # {'Film': 'bulworth_commandments'}, # {'Film': 'cheaper_clyde'}, # {'Film': 'color_philadelphia'}, # {'Film': 'elephant_trojan'}, # {'Film': 'gleaming_jawbreaker'}, # {'Film': 'human_graffiti'}, # {'Film': 'king_evolution'}, # {'Film': 'lady_stage'}, # {'Film': 'language_cowboy'}, # {'Film': 'mulholland_beast'}, # {'Film': 'oklahoma_jumanji'}, # {'Film': 'rules_human'}, # {'Film': 'splash_gump'}, # {'Film': 'vertigo_northwest'}, # {'Film': 'westward_seabiscuit'}, # {'Film': 'wizard_coldblooded'}] ### simple yes or no query dvd.query(pl.Expr(\"film_actor(academy_dinosaur, lucille_tracy)\")) # ['Yes'] actor_category Actor Category view to see in which categories an actor performed. dvd([\"actor_category(A, C) :- film_actor(F, A), film_category(F, C)\"]) jd = dvd.query(pl.Expr(\"actor_category(jennifer_davis, Category)\")) from pprint import pprint merged = {} for d in jd: for k, v in d.items(): if k not in merged: merged[k] = set() merged[k].add(v) pprint(merged) # {'Category': {'action', # 'animation', # 'comedy', # 'documentary', # 'drama', # 'family', # 'horror', # 'music', # 'new', # 'sci-fi', # 'sports', # 'travel'}} Saving knowledge base to prolog file Finally, let's now write those facts and rules to a prolog file. with open(\"dvd_rental.pl\", \"w\") as f: for i in dvd.db.keys(): for d in dvd.db[i][\"facts\"]: f.write(d.to_string() + \".\" + \"\\n\") f.close()","title":"Pytholog as a logic database"},{"location":"pytholog_database/#pytholog-as-a-logic-database","text":"","title":"Pytholog as a logic database"},{"location":"pytholog_database/#overview","text":"We will use DVD Rental database to feed a knowledge base as facts and rules, then logically query the database. Here we can find how to create the database in postgresql and insert the data. Let's connect to the database in python and see how it looks like: import psycopg2 import pandas as pd psql = psycopg2.connect(host = \"localhost\", database = \"dvdrental\", user = \"postgres\", password = \"password\") cursor = psql.cursor() ## fetch some data to confirm connection pd.read_sql(\"SELECT * FROM language;\", psql) # language_id name last_update # 0 1 English 2006-02-15 10:02:19 # 1 2 Italian 2006-02-15 10:02:19 # 2 3 Japanese 2006-02-15 10:02:19 # 3 4 Mandarin 2006-02-15 10:02:19 # 4 5 French 2006-02-15 10:02:19 # 5 6 German 2006-02-15 10:02:19 Let's see what the table names are: cursor.execute(\"select relname from pg_class where relkind='r' and relname !~ '^(pg_|sql_)';\") print(cursor.fetchall()) # [('actor',), ('store',), ('address',), ('category',), ('city',), ('country',), # ('customer',), ('film_actor',), ('film_category',), ('inventory',), ('language',), # ('rental',), ('staff',), ('payment',), ('film',), ('movies_rental',), ('compressed_movies_rental',)] def query_defn(table): return f\"SELECT * FROM {table};\"","title":"Overview"},{"location":"pytholog_database/#reading-tables-into-python","text":"No we will read the tables we will query into python and do some transformation to have values in lowercase. actor = pd.read_sql(query_defn(\"actor\"), psql) actor[\"Actor\"] = (actor[\"first_name\"] + \"_\" + actor[\"last_name\"]).str.lower() actor.head() # actor_id first_name ... last_update Actor # 0 1 Penelope ... 2013-05-26 14:47:57.620 penelope_guiness # 1 2 Nick ... 2013-05-26 14:47:57.620 nick_wahlberg # 2 3 Ed ... 2013-05-26 14:47:57.620 ed_chase # 3 4 Jennifer ... 2013-05-26 14:47:57.620 jennifer_davis # 4 5 Johnny ... 2013-05-26 14:47:57.620 johnny_lollobrigida # [5 rows x 5 columns] language = pd.read_sql(query_defn(\"language\"), psql) film = pd.read_sql(query_defn(\"film\"), psql) category = pd.read_sql(query_defn(\"category\"), psql) #customer = pd.read_sql(query_defn(\"customer\"), psql) language[\"name\"] = language[\"name\"].str.lower() film[\"title\"] = film[\"title\"].str.replace(\" \", \"_\").str.lower() category[\"name\"] = category[\"name\"].str.lower() #customer[\"Customer\"] = (customer[\"first_name\"] + \"_\" + customer[\"last_name\"]).str.lower() film_category = pd.read_sql(query_defn(\"film_category\"), psql) #film[film.film_id.isin(film_category[film_category.category_id == 14].film_id)] print(film.loc[film.film_id == 1, \"title\"]) # 4 academy_dinosaur # Name: title, dtype: object print(actor.head()) # actor_id first_name ... last_update Actor # 0 1 Penelope ... 2013-05-26 14:47:57.620 penelope_guiness # 1 2 Nick ... 2013-05-26 14:47:57.620 nick_wahlberg # 2 3 Ed ... 2013-05-26 14:47:57.620 ed_chase # 3 4 Jennifer ... 2013-05-26 14:47:57.620 jennifer_davis # 4 5 Johnny ... 2013-05-26 14:47:57.620 johnny_lollobrigida","title":"Reading tables into python"},{"location":"pytholog_database/#defining-knowledge-base","text":"Let's initiate the knowledge base and feed it with for loops. We will use rules as the query statements and views if we need some joining and conditions. import pytholog as pl dvd = pl.KnowledgeBase(\"dvd_rental\") for i in range(film.shape[0]): dvd([f\"film({film.film_id[i]}, {film.title[i]}, {film.language_id[i]})\"]) for i in range(language.shape[0]): dvd([f\"language({language.language_id[i]}, {language.name[i]})\"]) ## simple query dvd([\"film_language(F, L) :- film(_, F, LID), language(LID, L)\"]) dvd.query(pl.Expr(\"film_language(young_language, L)\")) # [{'L': 'english'}]","title":"Defining Knowledge Base"},{"location":"pytholog_database/#rules-as-views","text":"","title":"Rules as views"},{"location":"pytholog_database/#film_category","text":"We will create film_category view for i in range(category.shape[0]): dvd([f\"category({category.category_id[i]}, {category.name[i]})\"]) for i in range(film_category.shape[0]): dvd([f\"filmcategory({film_category.film_id[i]}, {film_category.category_id[i]})\"]) dvd([\"film_category(F, C) :- film(FID, F, _), filmcategory(FID, CID), category(CID, C)\"]) ## \"_\" to neglect this term ## another query to see what films in sci-fi category dvd.query(pl.Expr(\"film_category(F, sci-fi)\")) # [{'F': 'annie_identity'}, # {'F': 'armageddon_lost'}, # ..... # {'F': 'titans_jerk'}, # {'F': 'trojan_tomorrow'}, # {'F': 'unforgiven_zoolander'}, # {'F': 'vacation_boondock'}, # {'F': 'weekend_personal'}, # {'F': 'whisperer_giant'}, # {'F': 'wonderland_christmas'}]","title":"film_category"},{"location":"pytholog_database/#film_actor","text":"Let's join actors and films for i in range(actor.shape[0]): dvd([f\"actor({actor.actor_id[i]}, {actor.Actor[i]})\"]) film_actor = pd.read_sql(query_defn(\"film_actor\"), psql) #print(film_actor[film_actor[\"actor_id\"] == 3].shape) print(film_actor.shape) #(5462, 3) for i in range(film_actor.shape[0]): dvd([f\"filmactor({film_actor.film_id[i]}, {film_actor.actor_id[i]})\"]) dvd([\"film_actor(F, A) :- film(FID, F, _), filmactor(FID, AID), actor(AID, A)\"]) dvd.query(pl.Expr(\"film_actor(annie_identity, Actor)\")) #[{'Actor': 'adam_grant'}, {'Actor': 'cate_mcqueen'}, {'Actor': 'greta_keitel'}] ## query actors in a film dvd.query(pl.Expr(\"film_actor(academy_dinosaur, Actor)\")) # [{'Actor': 'penelope_guiness'}, # {'Actor': 'christian_gable'}, # {'Actor': 'lucille_tracy'}, # {'Actor': 'sandra_peck'}, # {'Actor': 'johnny_cage'}, # {'Actor': 'mena_temple'}, # {'Actor': 'warren_nolte'}, # {'Actor': 'oprah_kilmer'}, # {'Actor': 'rock_dukakis'}, # {'Actor': 'mary_keitel'}] ### query films that an actor performed in dvd.query(pl.Expr(\"film_actor(Film, penelope_guiness)\")) # [{'Film': 'academy_dinosaur'}, # {'Film': 'anaconda_confessions'}, # {'Film': 'angels_life'}, # {'Film': 'bulworth_commandments'}, # {'Film': 'cheaper_clyde'}, # {'Film': 'color_philadelphia'}, # {'Film': 'elephant_trojan'}, # {'Film': 'gleaming_jawbreaker'}, # {'Film': 'human_graffiti'}, # {'Film': 'king_evolution'}, # {'Film': 'lady_stage'}, # {'Film': 'language_cowboy'}, # {'Film': 'mulholland_beast'}, # {'Film': 'oklahoma_jumanji'}, # {'Film': 'rules_human'}, # {'Film': 'splash_gump'}, # {'Film': 'vertigo_northwest'}, # {'Film': 'westward_seabiscuit'}, # {'Film': 'wizard_coldblooded'}] ### simple yes or no query dvd.query(pl.Expr(\"film_actor(academy_dinosaur, lucille_tracy)\")) # ['Yes']","title":"film_actor"},{"location":"pytholog_database/#actor_category","text":"Actor Category view to see in which categories an actor performed. dvd([\"actor_category(A, C) :- film_actor(F, A), film_category(F, C)\"]) jd = dvd.query(pl.Expr(\"actor_category(jennifer_davis, Category)\")) from pprint import pprint merged = {} for d in jd: for k, v in d.items(): if k not in merged: merged[k] = set() merged[k].add(v) pprint(merged) # {'Category': {'action', # 'animation', # 'comedy', # 'documentary', # 'drama', # 'family', # 'horror', # 'music', # 'new', # 'sci-fi', # 'sports', # 'travel'}}","title":"actor_category"},{"location":"pytholog_database/#saving-knowledge-base-to-prolog-file","text":"Finally, let's now write those facts and rules to a prolog file. with open(\"dvd_rental.pl\", \"w\") as f: for i in dvd.db.keys(): for d in dvd.db[i][\"facts\"]: f.write(d.to_string() + \".\" + \"\\n\") f.close()","title":"Saving knowledge base to prolog file"},{"location":"pytholog_graph/","text":"Finding paths in graphs We will use pytholog library. We will define a weighted undirected graph for the largest MSAs in USA. Image and examples source is \"\"Classic Computer Science Problems in Python\" book. We first import the library and define the nodes and edges of the graph as prolog facts and rules. Define the knowledge base import pytholog as pl graph_kb = pl.KnowledgeBase(\"MSA_graph\") graph_kb([## routes between adjacent cities \"route(seattle, chicago, 1737)\", \"route(seattle, san_francisco, 678)\", \"route(san_francisco, riverside, 386)\", \"route(san_francisco, los_angeles, 348)\", \"route(los_angeles, riverside, 50)\", \"route(los_angeles, phoenix, 357)\", \"route(riverside, phoenix, 307)\", \"route(riverside, chicago, 1704)\", \"route(phoenix, dallas, 887)\", \"route(phoenix, houston, 1015)\", \"route(dallas, chicago, 805)\", \"route(dallas, atlanta, 721)\", \"route(dallas, houston, 225)\", \"route(houston, atlanta, 702)\", \"route(houston, miami, 968)\", \"route(atlanta, chicago, 588)\", \"route(atlanta, washington, 543)\", \"route(atlanta, miami, 604)\", \"route(miami, washington, 923)\", \"route(chicago, detroit, 238)\", \"route(detroit, boston, 613)\", \"route(detroit, washington, 396)\", \"route(detroit, new_york, 482)\", \"route(boston, new_york, 190)\", \"route(new_york, philadelphia, 81)\", \"route(philadelphia, washington, 123)\", ## define the rules how can we move from one point to another \"path(X, Y, P) :- route(X, Y, P)\", \"path(X, Y, P) :- route(X, Z, P2), path(Z, Y, P3), P is P2 + P3\", ## to make it undirected (two-way) graph #\"path(X, Y, P) :- route(Y, X, P)\", \"path(X, Y, P) :- route(Y, Z, P2), path(Z, X, P3), P is P2 + P3\" ]) We only needed to define the facts, the route between a city and its adjacent cities and the distance between them, then define the rule to traverse the graph searching for the path. Now let's search for some paths between some cities. pytholog uses Breadth-First Search algorithm to search for paths, So not always the result will be the shortest path but most of the cases it is. One more things the visited note returned when show_path = True, can be more than the one used to calculate the weight reponse, this is because the bfs search checks all nodes next to the current node and return it as visited, but you can see the actual path from the image which will lead to the result weight. Future implementations will support other kind of search algorithms. Path queries Examining cut and show_path functionalities . x, y = graph_kb.query(pl.Expr(\"path(boston, miami, Weight)\"), cut = True, show_path = True) ## cut argument to stop searching when a path is found print(x) print([x for x in y if str(x) > \"Z\"]) ## remove weights in the visited nodes # [{'Weight': 1317}] # ['washington', 'new_york', 'philadelphia'] The shortes possible path between the two cities! N.B. The path given isn't sorted. ## the other way x, y = graph_kb.query(pl.Expr(\"path(miami, boston, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': 1317}] # ['new_york', 'washington', 'philadelphia'] x, y = graph_kb.query(pl.Expr(\"path(seattle, washington, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': 2371}] # ['chicago', 'detroit'] x, y = graph_kb.query(pl.Expr(\"path(san_francisco, atlanta, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': 2678}] # ['houston', 'dallas', 'riverside', 'chicago'] Note here the weight is the second shortest path but it can be enhanced by better defining the facts and rules. Note also that the path given show \"Houston & Dallas\" but if you calculate the weights you will find that the algorithm never passed by them. It only passed to Riverside then Chicago then Atlanta. But the value is given because they were checked. x, y = graph_kb.query(pl.Expr(\"path(chicago, detroit, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': '238'}] # [] x, y = graph_kb.query(pl.Expr(\"path(los_angeles, dallas, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': 1244}] # ['phoenix'] x, y = graph_kb.query(pl.Expr(\"path(riverside, washington, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': 2338}] # ['miami', 'chicago', 'atlanta', 'detroit'] The lowest weight was given but again \"Miami\" was returned although when calculating the weights we will find out that the algorithm never passed by it but it checked it because of the return rule defined.","title":"Finding paths in graphs"},{"location":"pytholog_graph/#finding-paths-in-graphs","text":"We will use pytholog library. We will define a weighted undirected graph for the largest MSAs in USA. Image and examples source is \"\"Classic Computer Science Problems in Python\" book. We first import the library and define the nodes and edges of the graph as prolog facts and rules.","title":"Finding paths in graphs"},{"location":"pytholog_graph/#define-the-knowledge-base","text":"import pytholog as pl graph_kb = pl.KnowledgeBase(\"MSA_graph\") graph_kb([## routes between adjacent cities \"route(seattle, chicago, 1737)\", \"route(seattle, san_francisco, 678)\", \"route(san_francisco, riverside, 386)\", \"route(san_francisco, los_angeles, 348)\", \"route(los_angeles, riverside, 50)\", \"route(los_angeles, phoenix, 357)\", \"route(riverside, phoenix, 307)\", \"route(riverside, chicago, 1704)\", \"route(phoenix, dallas, 887)\", \"route(phoenix, houston, 1015)\", \"route(dallas, chicago, 805)\", \"route(dallas, atlanta, 721)\", \"route(dallas, houston, 225)\", \"route(houston, atlanta, 702)\", \"route(houston, miami, 968)\", \"route(atlanta, chicago, 588)\", \"route(atlanta, washington, 543)\", \"route(atlanta, miami, 604)\", \"route(miami, washington, 923)\", \"route(chicago, detroit, 238)\", \"route(detroit, boston, 613)\", \"route(detroit, washington, 396)\", \"route(detroit, new_york, 482)\", \"route(boston, new_york, 190)\", \"route(new_york, philadelphia, 81)\", \"route(philadelphia, washington, 123)\", ## define the rules how can we move from one point to another \"path(X, Y, P) :- route(X, Y, P)\", \"path(X, Y, P) :- route(X, Z, P2), path(Z, Y, P3), P is P2 + P3\", ## to make it undirected (two-way) graph #\"path(X, Y, P) :- route(Y, X, P)\", \"path(X, Y, P) :- route(Y, Z, P2), path(Z, X, P3), P is P2 + P3\" ]) We only needed to define the facts, the route between a city and its adjacent cities and the distance between them, then define the rule to traverse the graph searching for the path. Now let's search for some paths between some cities. pytholog uses Breadth-First Search algorithm to search for paths, So not always the result will be the shortest path but most of the cases it is. One more things the visited note returned when show_path = True, can be more than the one used to calculate the weight reponse, this is because the bfs search checks all nodes next to the current node and return it as visited, but you can see the actual path from the image which will lead to the result weight. Future implementations will support other kind of search algorithms.","title":"Define the knowledge base"},{"location":"pytholog_graph/#path-queries","text":"Examining cut and show_path functionalities . x, y = graph_kb.query(pl.Expr(\"path(boston, miami, Weight)\"), cut = True, show_path = True) ## cut argument to stop searching when a path is found print(x) print([x for x in y if str(x) > \"Z\"]) ## remove weights in the visited nodes # [{'Weight': 1317}] # ['washington', 'new_york', 'philadelphia'] The shortes possible path between the two cities! N.B. The path given isn't sorted. ## the other way x, y = graph_kb.query(pl.Expr(\"path(miami, boston, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': 1317}] # ['new_york', 'washington', 'philadelphia'] x, y = graph_kb.query(pl.Expr(\"path(seattle, washington, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': 2371}] # ['chicago', 'detroit'] x, y = graph_kb.query(pl.Expr(\"path(san_francisco, atlanta, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': 2678}] # ['houston', 'dallas', 'riverside', 'chicago'] Note here the weight is the second shortest path but it can be enhanced by better defining the facts and rules. Note also that the path given show \"Houston & Dallas\" but if you calculate the weights you will find that the algorithm never passed by them. It only passed to Riverside then Chicago then Atlanta. But the value is given because they were checked. x, y = graph_kb.query(pl.Expr(\"path(chicago, detroit, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': '238'}] # [] x, y = graph_kb.query(pl.Expr(\"path(los_angeles, dallas, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': 1244}] # ['phoenix'] x, y = graph_kb.query(pl.Expr(\"path(riverside, washington, Weight)\"), cut = True, show_path = True) print(x) [x for x in y if str(x) > \"Z\"] # [{'Weight': 2338}] # ['miami', 'chicago', 'atlanta', 'detroit'] The lowest weight was given but again \"Miami\" was returned although when calculating the weights we will find out that the algorithm never passed by it but it checked it because of the return rule defined.","title":"Path queries"}]}